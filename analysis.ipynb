{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **List to-do**\n",
    "\n",
    "- Remove the stop words from the list.\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Prepare the python environment**\n",
    "- !pip install -r requirements.txt\n",
    "- import nltk\n",
    "- nltk.download('punkt')\n",
    "- nltk.download('stopwords')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import pandas as pd\n",
    "\n",
    "data_dir = r'./data/'\n",
    "\n",
    "# Open the JSON file\n",
    "with open(f'{data_dir}/job_description_response.json') as file:\n",
    "    # Load the JSON data\n",
    "    data = json.load(file)\n",
    "\n",
    "# dataframe of skill: specific_skills.\n",
    "specific_skills_df = pd.DataFrame(data[0]['specific_skills'])\n",
    "\n",
    "# dataframe of skill: sector_skills.\n",
    "sector_skills_df = pd.DataFrame(data[0]['sector_skills'])\n",
    "\n",
    "# combine whole skill as single one.\n",
    "skills_df = pd.concat([specific_skills_df, sector_skills_df])\n",
    "\n",
    "# reseting the index \n",
    "skills_df = skills_df.reset_index(drop=True)\n",
    "\n",
    "# Convert the DataFrame to a CSV file\n",
    "skills_df.to_csv(f'{data_dir}requested_skills.csv', index=False)\n",
    "\n",
    "# dataframe structure of the resume\n",
    "resume_df = pd.read_csv(f'{data_dir}/resumes.csv')\n",
    "\n",
    "# dataframe structure of the sample result\n",
    "sample_submission_df = pd.read_csv(f'{data_dir}/sample_submission.csv')\n",
    "\n",
    "# dataframe structure of the resume\n",
    "resume_df = pd.read_csv(f'{data_dir}/resumes.csv')\n",
    "\n",
    "# dataframe structure of the sample result\n",
    "sample_submission_df = pd.read_csv(f'{data_dir}/sample_submission.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dict_keys(['_id', 'location', 'title', 'organisation', 'description', 'specific_skills', 'sector_skills'])\n",
      "\n",
      "location: AAAAAAAAA (AAAAAAAAAAAAAA, AAAAAAAAAAAAA, BELGIUM)\n",
      "title: Business Analyst Customer Service\n",
      "organisation: AAAAAAAAAAAAAA\n",
      "\n",
      "Business Analyst Customer Service\n",
      "\n",
      "specific_skills\n",
      "                                               title        weigth\n",
      "0  Demonstrated experience within the Belgian ene...   Should have\n",
      "1  Demonstrated experience with writing processes...   Should have\n",
      "2                   Demonstrated experience with SAP   Should have\n",
      "3      Demonstrated experience in training end users  Nice to have\n",
      "4  Candidate adds a document showing demonstrable...  Nice to have\n",
      "\n",
      "sector_skills\n",
      "                                               title     weigth\n",
      "0  Demonstrated experience as a business analyst ...  Must have\n",
      "1  Demonstrated experience with business process ...  Must have\n",
      "2  Demonstrated experience with stakeholder manag...  Must have\n",
      "\n",
      "   index                                              title        weigth\n",
      "0      0  Demonstrated experience within the Belgian ene...   Should have\n",
      "1      1  Demonstrated experience with writing processes...   Should have\n",
      "2      2                   Demonstrated experience with SAP   Should have\n",
      "3      3      Demonstrated experience in training end users  Nice to have\n",
      "4      4  Candidate adds a document showing demonstrable...  Nice to have\n",
      "5      0  Demonstrated experience as a business analyst ...     Must have\n",
      "6      1  Demonstrated experience with business process ...     Must have\n",
      "7      2  Demonstrated experience with stakeholder manag...     Must have\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(data[0].keys())\n",
    "print()\n",
    "\n",
    "\n",
    "for key_name in list(data[0].keys())[1:4]:\n",
    "    print(f\"{key_name}: {data[0][key_name]}\")\n",
    "print()\n",
    "\n",
    "print(data[0]['title'])\n",
    "print()\n",
    "\n",
    "print('specific_skills')\n",
    "specific_skills_df = pd.DataFrame(data[0]['specific_skills'])\n",
    "print(specific_skills_df)\n",
    "print()\n",
    "\n",
    "print('sector_skills')\n",
    "sector_skills_df = pd.DataFrame(data[0]['sector_skills'])\n",
    "print(sector_skills_df)\n",
    "print()\n",
    "\n",
    "# Concatenate the two DataFrames\n",
    "concatenated_df = pd.concat([specific_skills_df, sector_skills_df])\n",
    "print(concatenated_df.reset_index())\n",
    "print()\n",
    "\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data prepration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import word_tokenize\n",
    "\n",
    "# Get the list of stopwords\n",
    "stop_words = set(stopwords.words())\n",
    "\n",
    "# take string as input > remove the stop words > return filtered string\n",
    "def remove_stopwords(string: str, stop_words=stop_words) -> str:\n",
    "    # Set the input string\n",
    "    input_string = string # \"This is a sample sentence with some stop words.\"\n",
    "\n",
    "    # Tokenize the input string into words\n",
    "    words = word_tokenize(input_string)\n",
    "\n",
    "    # Remove the stopwords from the tokenized words\n",
    "    filtered_words = [word for word in words if word.casefold() not in stop_words]\n",
    "\n",
    "    # Join the filtered words back into a string\n",
    "    filtered_string = ' '.join(filtered_words)\n",
    "\n",
    "    # Print the filtered string\n",
    "    return filtered_string\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(remove_stopwords(resume_df[' resume_text'][0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(sample_submission_df.sort_values('rank'))\n",
    "# Access the data\n",
    "#print(formatted_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(data[0].keys())\n",
    "print(data[0]['specific_skills'])\n",
    "print(data[0]['sector_skills'])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "sl",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
