{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **Building Functions**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Matches repeated A (More than 1) and subs with a space\n",
    "def remove_repeated_letters(text):\n",
    "    pattern = r'(A)\\1+'  \n",
    "    return re.sub(pattern, ' ', text)\n",
    "\n",
    "\n",
    "def sum_tuples(lists):\n",
    "    result = {}\n",
    "\n",
    "    # Iterate over each list of tuples\n",
    "    for lst in lists:\n",
    "        # Add values from the current list to the result dictionary\n",
    "        for key, value in lst:\n",
    "            result[key] = result.get(key, 0) + value\n",
    "\n",
    "    return result\n",
    "\n",
    "\n",
    "# multiplies the values of the 2 dictionaries with the same keys\n",
    "def multiply_dictionary_values(dictionary, multiplier):\n",
    "    result = {}\n",
    "\n",
    "    for key, value in dictionary.items():\n",
    "        result[key] = value * multiplier\n",
    "\n",
    "    return result\n",
    "\n",
    "# divides the values of the 2 dictionaries with the same keys\n",
    "def divide_dictionary_values(dictionary, divider):\n",
    "    result = {}\n",
    "\n",
    "    # divides the values and update the dictionary\n",
    "    for key, value in dictionary.items():\n",
    "        result[key] = value / divider\n",
    "\n",
    "    return result\n",
    "\n",
    "\n",
    "# sums the values of the 2 dictionaries with the same keys\n",
    "def sum_dicts(dict1, dict2):\n",
    "    sum_dict = {}\n",
    "\n",
    "    for key in dict1:\n",
    "        if key in dict2:\n",
    "            sum_dict[key] = dict1[key] + dict2[key]\n",
    "\n",
    "    return sum_dict\n",
    "\n",
    "# ranks list of profiles based on single requirement\n",
    "def rank_profiles(profiles, requirement,weight_value):\n",
    "    \n",
    "    # Step 1: Preprocessing\n",
    "    vectorizer = TfidfVectorizer()\n",
    "    profile_vectors = vectorizer.fit_transform(profiles)\n",
    "    # desc_vector = vectorizer.transform([description])\n",
    "    req_vector = vectorizer.transform([requirement])\n",
    "\n",
    "    # Step 2: Calculate Cosine Similarity for each profile\n",
    "    # cosine_sims = cosine_similarity(desc_vector, profile_vectors)\n",
    "    req_sims = cosine_similarity(req_vector, profile_vectors)\n",
    "    # weighted_sims = cosine_sims * req_sims\n",
    "\n",
    "    # Step 3: Rank the Profiles\n",
    "    rankings = sorted(enumerate(req_sims[0]), key=lambda x: x[1], reverse=True)   \n",
    "    rankings = [(key, value * float(weight_value)) for key, value in rankings]\n",
    "    return rankings\n",
    "\n",
    "\n",
    "# weighting requirement and job describtion differently\n",
    "def weight_features(description_weight,requirement_weight,description_ranking,requirements_rankings,requirements):\n",
    "    # nuterlizing sum of 8 different requiremnet ranking to level down to sigle describtion \n",
    "    requirement_ranking_neutral_weight = divide_dictionary_values(requirements_rankings,len(requirements))\n",
    "\n",
    "    # weighting the resume based on weights value \n",
    "    weighted_description_ranking = multiply_dictionary_values(description_ranking, description_weight)\n",
    "    weighted_requirement_ranking = multiply_dictionary_values(requirement_ranking_neutral_weight, requirement_weight)\n",
    "\n",
    "    # returing the sum of multiplied weigths \n",
    "    return sum_dicts(weighted_requirement_ranking,weighted_description_ranking)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **Running Application**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import re\n",
    "\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "\n",
    "dir_location = r\"./data\"\n",
    "\n",
    "#reads resume cv as dataframe\n",
    "resumes =  pd.read_csv(f\"{dir_location}/resumes.csv\")\n",
    "\n",
    "# replace 'Belangrijkste vaardigheden' to 'Top Skills' from string\n",
    "resumes[\" resume_text\"] = list(resumes[\" resume_text\"].replace('Belangrijkste vaardigheden', 'Top Skills', regex=True).values)\n",
    "\n",
    "\n",
    "# list of filtered/clean resume, remove repeated A's (censored info.), replacing multiple space to single space.\n",
    "processed_resumes = []\n",
    "for indx, row in resumes.iterrows():\n",
    "    processed_resumes.append(re.sub(r\"\\s+\", \" \",remove_repeated_letters(resumes[\" resume_text\"].values[indx])))\n",
    "\n",
    "# assign the list of processed text to a column 'processed_text'\n",
    "resumes[\"processed_text\"] = processed_resumes\n",
    "\n",
    "# readuing the job description from json file\n",
    "description_df = pd.read_json(f\"{dir_location}/job_description_response.json\")\n",
    "\n",
    "\n",
    "# creating the list of the requirement for the jobs\n",
    "requirements = []\n",
    "for index, row in description_df.iterrows():\n",
    "    # Apply a lambda function to iterate over each value in the row\n",
    "    row_values = row.apply(lambda x: x if isinstance(x, list) else [])\n",
    "    \n",
    "    # Iterate over the row values until you reach elements of a list\n",
    "    for value in row_values:\n",
    "        if isinstance(value, list):\n",
    "            for element in value:\n",
    "                requirements.append(element[\"title\"])\n",
    "                #print(f'List element: {element[\"title\"]}')\n",
    "\n",
    "        else:\n",
    "            print(f'Non-list value: {value}')\n",
    "\n",
    "# creting the list of resumes to cross check with reqirements\n",
    "profiles = list(resumes[\"processed_text\"].values)\n",
    "\n",
    "# listing the requirement weight from json\n",
    "requirement_weights = []\n",
    "for value in row_values:\n",
    "    if isinstance(value, list):\n",
    "        for element in value:\n",
    "            requirement_weights.append(element[\"weigth\"])\n",
    "            #print(f'List element: {element[\"weigth\"]}')\n",
    "    else:\n",
    "        print(f'Non-list value: {value}')\n",
    "\n",
    "# lable the string weights to intiger\n",
    "label_mapping = {'Nice to have': 1, 'Should have': 2, 'Must have': 3}\n",
    "requirement_weights = [label_mapping[label] for label in requirement_weights]\n",
    "\n",
    "# cleaing the description text\n",
    "description = remove_repeated_letters(\"The two former companies AAAAAAA and AAAAAAA have merged their processes and software for AAAAAAAA into 1 process in 1 AAAAAAA system. In order to optimize our systems and implement a number of requested legal changes, we are looking for an analyst to lead and support the Premiums project that has been set up. Together with the project leader and fellow analysts, you ensure a successful implementation of these projects.\\nAs a functional analyst, you ensure high-quality and coherent processes by analyzing new and changed processes, initiating proposals for adaptation and by optimizing in the context of an integration of these processes in the existing process structure\\no Together with business and ICT you make an analysis of the proposed improvements and new needs.\\no Write out use cases and discuss them with users and ICT. These use cases are the basis for ICT developments, extending UAT testing and drawing up training and user manuals\\no Supervising testing and testing yourself\\no Providing training or supporting trainers\\no Training key users for further maintenance and testing of the S4Hana system\\no Developing processes and drawing up process documentation in collaboration with business and ICT\")\n",
    "\n",
    "# list the rankings for indivitual requirements\n",
    "requirements_rankings = []\n",
    "for indx,requirement in enumerate(requirements):\n",
    "    requirements_rankings.append(rank_profiles(profiles, requirement,requirement_weights[indx]))\n",
    "\n",
    "# suming up all the cosin similarity values bases on the same/single profile\n",
    "requirements_rankings = sum_tuples(requirements_rankings)\n",
    "\n",
    "# sorting out profiles scores based on hight to low\n",
    "requirements_rankings = dict(sorted(requirements_rankings.items(), key=lambda item: item[1],reverse=True))\n",
    "\n",
    "# ranking the profile based on the description\n",
    "description_ranking = []\n",
    "description_ranking.append(rank_profiles(profiles,description,1))\n",
    "\n",
    "# suming up all the cosin similarity values bases on the same/single profile\n",
    "description_ranking = sum_tuples(description_ranking)\n",
    "\n",
    "# implementing the weighting function\n",
    "main_rankings = weight_features(0.2,0.8,description_ranking,requirements_rankings,requirements)\n",
    "\n",
    "# sorting the values for ranking\n",
    "main_rankings = dict(sorted(main_rankings.items(), key=lambda x: x[1],reverse=True))\n",
    "\n",
    "# Visualizing the dinformation\n",
    "new_keys = []\n",
    "for key,value in main_rankings.items():\n",
    "    #print(\"key: \",resumes[\"id\"].values[key],\"   \",\"value: \",value)\n",
    "    new_keys.append(resumes[\"id\"].values[key])\n",
    "\n",
    "# number to applicant name\n",
    "main_rankings = {new_keys[i]: value for i, value in enumerate(main_rankings.values())}# create data frame\n",
    "\n",
    "# creating a CSV files\n",
    "pd.DataFrame(main_rankings.items(), columns=[\"applicant\",\"value\"]).to_csv('result_ranking.csv')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **Analysis**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# check the keyword/(' sap ') if it present in the resume, ignore case sensitivity  'flags=re.I'\n",
    "mask2= resumes[\" resume_text\"].str.contains(\" sap \", case=False,regex=True,flags=re.I)\n",
    "resumes[mask2]\n",
    "\n",
    "# patten analysis: we find job title after keyword/'Top Skills'\n",
    "mask = resumes[\" resume_text\"].str.contains(\"Top Skills\", case=False)\n",
    "resumes[mask]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "document_understanding",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
